{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.001, n_iters=1000):\n",
    "        self.lr = learning_rate  # Tốc độ học\n",
    "        self.n_iters = n_iters  # Số lần lặp lại\n",
    "        self.weights = None  # Trọng số sẽ được khởi tạo sau\n",
    "        self.bias = None  # Bias sẽ được khởi tạo sau\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape  # Lấy số lượng mẫu và đặc trưng từ dữ liệu đầu vào\n",
    "\n",
    "        # Khởi tạo tham số\n",
    "        self.weights = np.zeros(n_features)  # Khởi tạo trọng số bằng 0\n",
    "        self.bias = 0  # Khởi tạo bias bằng 0\n",
    "\n",
    "        # Gradient descent\n",
    "        for _ in range(self.n_iters):\n",
    "            # Gần đúng y bằng tổ hợp tuyến tính của trọng số và X, cộng bias\n",
    "            linear_model = np.dot(X, self.weights) + self.bias\n",
    "            # Áp dụng hàm sigmoid\n",
    "            y_predicted = self._sigmoid(linear_model)\n",
    "\n",
    "            # Tính toán gradient\n",
    "            dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))  # Gradient của trọng số\n",
    "            db = (1 / n_samples) * np.sum(y_predicted - y)  # Gradient của bias\n",
    "            # Cập nhật tham số\n",
    "            self.weights -= self.lr * dw  # Cập nhật trọng số\n",
    "            self.bias -= self.lr * db  # Cập nhật bias\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_model = np.dot(X, self.weights) + self.bias  # Gần đúng y bằng tổ hợp tuyến tính của trọng số và X, cộng bias\n",
    "        y_predicted = self._sigmoid(linear_model)  # Áp dụng hàm sigmoid\n",
    "        y_predicted_cls = [1 if i > 0.5 else 0 for i in y_predicted]  # Chuyển đổi thành nhãn lớp\n",
    "        return np.array(y_predicted_cls)\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))  # Hàm sigmoid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_36604\\256517472.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data['diagnosis'] = data['diagnosis'].replace({'M': 1, 'B': 0})\n"
     ]
    }
   ],
   "source": [
    "url = \"./breast-cancer.csv\"\n",
    "data = pd.read_csv(url)\n",
    "data.drop(columns=[\"id\"], inplace=True)\n",
    "data['diagnosis'] = data['diagnosis'].replace({'M': 1, 'B': 0})\n",
    "\n",
    "# Split features and target variable\n",
    "X = data.drop(columns=['diagnosis'])\n",
    "y = data['diagnosis']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1234\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR classification accuracy: 0.9298245614035088\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate accuracy function\n",
    "def accuracy(y_true, y_pred):\n",
    "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "    return accuracy\n",
    "\n",
    "# Instantiate and fit the Logistic Regression model\n",
    "regressor = LogisticRegression(learning_rate=0.0001, n_iters=1000)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = regressor.predict(X_test)\n",
    "\n",
    "# Print accuracy\n",
    "print(\"LR classification accuracy:\", accuracy(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[67  2]\n",
      " [ 6 39]]\n",
      "Precision: 0.9512195121951219\n",
      "Recall: 0.8666666666666667\n",
      "F1-score: 0.9069767441860465\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "# Tính ma trận nhầm lẫn\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Tính precision, recall và F1-score\n",
    "precision = precision_score(y_test, predictions)\n",
    "recall = recall_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ma trận nhầm lẫn (Confusion Matrix):\n",
    "\n",
    "Ma trận nhầm lẫn là một bảng mô tả hiệu suất của một mô hình phân loại trên một tập dữ liệu thử nghiệm, trong đó các hàng biểu diễn các nhãn thực tế và các cột biểu diễn các nhãn được dự đoán bởi mô hình.\n",
    "Cụ thể, nó bao gồm bốn ô:\n",
    "Ô chính xác dương (True Positive - TP): Các trường hợp mà mô hình dự đoán đúng là positive (1) khi thực tế chúng là positive.\n",
    "Ô chính xác âm (True Negative - TN): Các trường hợp mà mô hình dự đoán đúng là negative (0) khi thực tế chúng là negative.\n",
    "Ô sai dương (False Positive - FP): Các trường hợp mà mô hình dự đoán positive (1) nhưng thực tế chúng là negative (0).\n",
    "Ô sai âm (False Negative - FN): Các trường hợp mà mô hình dự đoán negative (0) nhưng thực tế chúng là positive (1).\n",
    "Precision (Độ chính xác):\n",
    "\n",
    "Precision là tỷ lệ của các trường hợp positive được dự đoán đúng (TP) so với tổng số các trường hợp được dự đoán là positive (TP + FP).\n",
    "Precision cung cấp thông tin về tỷ lệ các trường hợp dự đoán là positive thực sự là positive. Nó là một chỉ số quan trọng khi chi phí của việc dự đoán sai positive (FP) cao.\n",
    "Recall (Tỷ lệ phát hiện đúng):\n",
    "\n",
    "Recall là tỷ lệ của các trường hợp positive được dự đoán đúng (TP) so với tổng số các trường hợp thực tế là positive (TP + FN).\n",
    "Recall cung cấp thông tin về khả năng của mô hình trong việc phát hiện tất cả các trường hợp positive. Điều này quan trọng khi việc bỏ sót các trường hợp positive (FN) có thể có hậu quả nghiêm trọng.\n",
    "F1-score:\n",
    "\n",
    "F1-score là một số đo kết hợp của precision và recall, được tính bằng trung bình điều hòa của chúng.\n",
    "F1-score cung cấp một cách tổng quan về hiệu suất của mô hình, bằng cách cân nhắc cả precision và recall. Nó là một phép đo hữu ích khi bạn muốn cân nhắc cả sự chính xác và khả năng phát hiện của mô hình."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
